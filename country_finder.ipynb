{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.utils.results_utils import mapper\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"static\"\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        try:\n",
    "            temp = pd.read_excel(os.path.join(folder, file), sheet_name=\"Data\")\n",
    "        except:\n",
    "            temp = pd.read_excel(os.path.join(folder, file), sheet_name=\"Sheet 1\")\n",
    "        df = pd.concat([df, temp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_df = pd.read_excel(\"../../MV Maids All Steps.xlsx\", sheet_name=\"Sheet 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_df.ffill(inplace=True)\n",
    "df.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = accepted_df[[\"Maid ID\", \"Maid Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[[\"Maid’s ID\", \"Modified Field\", \"Maid’s Nationality\", \"Agent Value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.merge(ids, how=\"inner\", left_on=\"Maid’s ID\", right_on=\"Maid ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = target[target[\"Modified Field\"] == \"Birth Place\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = places.drop_duplicates(subset=[\"Maid’s Nationality\", \"Agent Value\", \"Maid’s ID\"])[\"Agent Value\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maid’s ID</th>\n",
       "      <th>Modified Field</th>\n",
       "      <th>Maid’s Nationality</th>\n",
       "      <th>Agent Value</th>\n",
       "      <th>Maid ID</th>\n",
       "      <th>Maid Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1034657</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034658</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034659</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034660</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034661</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508252</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508253</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508254</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508255</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508256</th>\n",
       "      <td>77581.0</td>\n",
       "      <td>Birth Place</td>\n",
       "      <td>Ethiopian</td>\n",
       "      <td>WOLAYETA</td>\n",
       "      <td>77581.0</td>\n",
       "      <td>BELAYNESH BEKELE YOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Maid’s ID Modified Field Maid’s Nationality Agent Value  Maid ID  \\\n",
       "1034657    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "1034658    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "1034659    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "1034660    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "1034661    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "...            ...            ...                ...         ...      ...   \n",
       "2508252    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "2508253    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "2508254    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "2508255    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "2508256    77581.0    Birth Place          Ethiopian    WOLAYETA  77581.0   \n",
       "\n",
       "                     Maid Name  \n",
       "1034657  BELAYNESH BEKELE YOTE  \n",
       "1034658  BELAYNESH BEKELE YOTE  \n",
       "1034659  BELAYNESH BEKELE YOTE  \n",
       "1034660  BELAYNESH BEKELE YOTE  \n",
       "1034661  BELAYNESH BEKELE YOTE  \n",
       "...                        ...  \n",
       "2508252  BELAYNESH BEKELE YOTE  \n",
       "2508253  BELAYNESH BEKELE YOTE  \n",
       "2508254  BELAYNESH BEKELE YOTE  \n",
       "2508255  BELAYNESH BEKELE YOTE  \n",
       "2508256  BELAYNESH BEKELE YOTE  \n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places[places[\"Agent Value\"] == \"WOLAYETA\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique places and nationalities\n",
    "places_unique = places[[\"Maid’s ID\", \"Maid’s Nationality\", \"Agent Value\"]].drop_duplicates(subset=[\"Maid’s Nationality\", \"Agent Value\"])\n",
    "\n",
    "# Normalize nationality to country code using mapper\n",
    "def get_country_code(nationality):\n",
    "    # Use fuzzy matching to find the closest key in mapper\n",
    "    matched_country, score = process.extractOne(nationality, mapper.keys())\n",
    "    return mapper.get(matched_country, \"XXX\")\n",
    "\n",
    "places_unique[\"country_code\"] = places_unique[\"Maid’s Nationality\"].apply(get_country_code)\n",
    "\n",
    "# Prepare DataFrame for custom_cities.csv format\n",
    "places_to_add = places_unique[[\"Agent Value\", \"country_code\"]].rename(columns={\"Agent Value\": \"name\"})\n",
    "\n",
    "len(places_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_with_counts = places_to_add.merge(\n",
    "    right=counts,\n",
    "    left_on=\"name\",\n",
    "    right_on=\"Agent Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by country code then count\n",
    "places_with_counts.sort_values(by=[\"country_code\", \"count\"], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_with_counts.to_csv(\"issueplaces_with_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_to_add.to_csv(\"birthplaces.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = target[target[\"Modified Field\"] == \"Passport Place(EN)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent Value\n",
       "PCG DUBAI                619\n",
       "MOFA                     215\n",
       "DFA MANILA               214\n",
       "PE ABU DHABI             204\n",
       "GOVERNMENT OF KENYA      170\n",
       "ETHIOPIA                 169\n",
       "COLOMBO                  140\n",
       "UGANDA GOVT KAMPALA      116\n",
       "COCHIN                    86\n",
       "REGISTRAR GENERAL HRE     59\n",
       "DUBAI                     54\n",
       "PE RIYADH                 42\n",
       "DFA DAVAO                 41\n",
       "TRIVANDRUM                41\n",
       "DFA PAMPANGA              38\n",
       "DFA ILOILO                37\n",
       "PCG HONG KONG             35\n",
       "JALANDHAR                 35\n",
       "DFA GENERAL SANTOS        34\n",
       "BENGALURU                 34\n",
       "DFA NCR SOUTH             33\n",
       "KOLKATA                   33\n",
       "DFA NCR WEST              30\n",
       "DFA BACOLOD               29\n",
       "DFA LUCENA                27\n",
       "DFA TUGUEGARAO            26\n",
       "DFA NCR NORTHEAST         24\n",
       "DFA NCR NORTH             23\n",
       "DFA SANTIAGO CITY         23\n",
       "DFA LA UNION              23\n",
       "PE DOHA                   22\n",
       "KOZHIKODE                 22\n",
       "PE KUWAIT                 21\n",
       "DFA ANGELES               21\n",
       "DFA NCR EAST              20\n",
       "DFA BUTUAN                20\n",
       "DFA CAGAYAN DE ORO        20\n",
       "DFA CEBU                  20\n",
       "SMST                      20\n",
       "DFA LEGAZPI               19\n",
       "VISAKHAPATNAM             19\n",
       "DFA TACLOBAN              18\n",
       "DFA BATANGAS              18\n",
       "DFA TAGUM                 16\n",
       "DFA ILOCOS NORTE          15\n",
       "PE BEIRUT                 15\n",
       "CHANDIGARH                15\n",
       "MUMBAI                    14\n",
       "GOVT UGANDA KAMPALA       14\n",
       "DFA CALASIAO              14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.drop_duplicates(subset=[\"Maid’s Nationality\", \"Agent Value\", \"Maid’s ID\"])[\"Agent Value\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique places and nationalities\n",
    "places_unique = places[[\"Maid’s ID\", \"Maid’s Nationality\", \"Agent Value\"]].drop_duplicates(subset=[\"Maid’s Nationality\", \"Agent Value\"])\n",
    "\n",
    "# Normalize nationality to country code using mapper\n",
    "def get_country_code(nationality):\n",
    "    # Use fuzzy matching to find the closest key in mapper\n",
    "    matched_country, score = process.extractOne(nationality, mapper.keys())\n",
    "    return mapper.get(matched_country, \"XXX\")\n",
    "\n",
    "places_unique[\"country_code\"] = places_unique[\"Maid’s Nationality\"].apply(get_country_code)\n",
    "\n",
    "# Prepare DataFrame for custom_cities.csv format\n",
    "places_to_add = places_unique[[\"Agent Value\", \"country_code\"]].rename(columns={\"Agent Value\": \"name\"})\n",
    "\n",
    "len(places_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_to_add.to_csv(\"issueplaces.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G GENEROSO DV OR 1 [[85982.0]] G GENEROSO DVO OR 1 [[75564.0]] \n",
      "SN FERNANDO CEBU 1 [[77522.0]] SAN FERNANDO CEBU 1 [[89837.0]] \n",
      "MATALAM NO COT 1 [[86862.0]] MATALAM N COT 1 [[88297.0]] \n",
      "SANCHEZ MIRA CAG 1 [[86967.0]] SANCHEZ MIRA CAGE 1 [[92705.0]] \n",
      "ALLANERA N ECIJA 1 [[86928.0]] LLANERA N ECIJA 1 [[84366.0]] \n",
      "KIDAPAWAN NO COT 1 [[84771.0]] KIDAPAWAN NO CO 1 [[91712.0]] \n",
      "SAN FERNANDO PMP 1 [[85775.0]] SAN FERNANDO PAMP 1 [[87102.0]] \n",
      "SAN LUIS PAMPANGA 1 [[87416.0]] SN LUIS PAMPANGA 1 [[85282.0]] \n",
      "LAGUINDINGAN MO 1 [[85280.0]] LAGUINDINGAN M O 1 [[86057.0]] \n",
      "BANGA S COTABATO 1 [[84942.0]] BANGA SO COTABATO 1 [[91688.0]] \n",
      "GAPAN N ECIJA 1 [[80319.0]] GAPAN NECIJA 1 [[86087.0]] \n",
      "KALIBO AKLAN 1 [[80321.0]] KALIBO KLAN 1 [[80321.0]] \n",
      "VALENCIA BKN 1 [[82897.0]] VALECIA BKN 1 [[93211.0]] \n",
      "MINGLANILA CEBU 1 [[80334.0]] MINGLANILLA CEBU 1 [[84856.0]] \n",
      "LAPU LAPU CEBU 2 [[84450.0]] LAPULAPU CEBU 1 [[81000.0]] \n",
      "APARRI CAGAYAN 1 [[87029.0]] APARRI AGAYAN 1 [[82652.0]] \n",
      "DUPAX DN N VIZ 2 [[83243.0]] DUPA DN N VIZ 1 [[90857.0]] \n",
      "SN JUAN BATANGAS 2 [[86175.0]] SAN JUAN BATANGAS 1 [[85471.0]] \n",
      "SN FRANCISCO ADS 1 [[87103.0]] SAN FRANCISCO ADS 1 [[83020.0]] \n",
      "DATU SINSUAT MGD 2 [[86785.0]] DATU SINSUAT MGDE 1 [[91044.0]] \n",
      "LAS NIEVES ADN 1 [[82205.0]] LAS NIEVES AD 1 [[83776.0]] \n",
      "S BENEDICTO N OC 1 [[87203.0]] S BENEDICTON OC 1 [[87203.0]] \n",
      "CALATRAVA NEG OC 1 [[80649.0]] CALATRAVA NEG OCC 1 [[86463.0]] \n",
      "TALAVERA N ECIJA 1 [[82777.0]] TALAVERA NECIJA 1 [[88478.0]] \n",
      "MLANG NO COT 1 [[86219.0]] MLANG N COT 1 [[88591.0]] \n",
      "ESPERANZA S KUD 2 [[85468.0]] ESPERANZAS KUD 1 [[79231.0]] \n",
      "DATU PAGLAS MGD 1 [[80860.0]] DATU PAGLAS MD 1 [[80860.0]] \n",
      "TALIPAO SLU 1 [[86912.0]] TALIPAO SULU 1 [[77606.0]] \n",
      "OROQUIETA CITY 1 [[81061.0]] OROQUETA CITY 1 [[83775.0]] \n",
      "BACUJAG SGO DN 1 [[86161.0]] BACUAG SGO DN 1 [[93217.0]] \n",
      "ARAYAT PAMPANGA 1 [[80991.0]] RAYAT PAMPANGA 1 [[78100.0]] \n",
      "STA FE N VIZ 1 [[86918.0]] STA FEN VIZ 1 [[77923.0]] \n",
      "STO DOMINGO I S 1 [[82628.0]] STO DOMINGO IS 1 [[82628.0]] \n",
      "SN ILDEFONSO BUL 1 [[83057.0]] SAN ILDEFONSO BUL 1 [[77264.0]] \n",
      "CALAPAN OR MDO 1 [[85789.0]] CALAPAN OR MDOD 1 [[88856.0]] \n",
      "MANAY DVAO OR 1 [[83890.0]] MANAY DVO OR 1 [[90633.0]] \n",
      "DAANBANTAYAN CEB 1 [[86023.0]] DAANBANTAYAN CEBU 1 [[88625.0]] \n",
      "D O SINSUAT MGD 1 [[88544.0]] DO SINSUAT MGD 1 [[92813.0]] \n",
      "CLAVERIA CAGAYA 1 [[90569.0]] CLAVERIA CAGAYAN 1 [[89506.0]] \n",
      "CAG DE ORO MS OR 1 [[88110.0]] CAG DE ORO MIS OR 1 [[75317.0]] \n",
      "SN ISIDRO NO SMR 1 [[79980.0]] SAN ISIDRO NO SMR 1 [[71386.0]] \n",
      "PULUPANDAN N OC 1 [[91721.0]] PULUPANDANN OC 1 [[79933.0]] \n",
      "ALAMADA NO COT 1 [[79304.0]] ALAMADA N COT 1 [[84916.0]] \n",
      "STA CATALINA IS 1 [[88074.0]] STA CATALINA I S 1 [[77920.0]] \n",
      "SN MIGUEL SGO DS 1 [[74885.0]] SAN MIGUEL SGO DS 1 [[92177.0]] \n"
     ]
    }
   ],
   "source": [
    "# Identify similar city names within each country code\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set similarity threshold\n",
    "similarity_threshold = 95  # Adjust as needed (higher = stricter matching)\n",
    "\n",
    "# Group places by country code\n",
    "country_groups = places_to_add.groupby('country_code')\n",
    "\n",
    "# Dictionary to store similar place clusters for each country\n",
    "similar_places = defaultdict(list)\n",
    "\n",
    "# Process each country's places\n",
    "for country_code, group in country_groups:\n",
    "    places_list = group['name'].tolist()\n",
    "    \n",
    "    # Skip processing if too few places\n",
    "    if len(places_list) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Find similar places within this country\n",
    "    processed = set()\n",
    "    \n",
    "    for i, place1 in enumerate(places_list):\n",
    "        if place1 in processed:\n",
    "            continue\n",
    "            \n",
    "        cluster = [place1]\n",
    "        processed.add(place1)\n",
    "        \n",
    "        for place2 in places_list[i+1:]:\n",
    "            if place2 in processed:\n",
    "                continue\n",
    "                \n",
    "            # Calculate similarity ratio\n",
    "            similarity = fuzz.ratio(place1, place2)\n",
    "            \n",
    "            # If similar enough, add to cluster\n",
    "            if similarity >= similarity_threshold:\n",
    "                cluster.append(place2)\n",
    "                processed.add(place2)\n",
    "        \n",
    "        # Store cluster if it contains multiple places\n",
    "        if len(cluster) > 1:\n",
    "            similar_places[country_code].append(cluster)\n",
    "\n",
    "place_counts = places_to_add['name'].value_counts().to_dict()\n",
    "\n",
    "# Create a DataFrame with all similar place clusters for easier inspection\n",
    "similar_df_rows = []\n",
    "country = \"PHL\"\n",
    "clusters = similar_places[country]\n",
    "\n",
    "for cluster in clusters:\n",
    "    for place in cluster:\n",
    "        print(place, place_counts.get(place, 0), place_ids[place_ids['name'] == place]['Maid’s ID'].tolist(), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reviewing similar_places.csv, create a mapping of misspelled names to correct names\n",
    "# For example:\n",
    "corrections = {\n",
    "    # 'MISSPELLED': 'CORRECT',\n",
    "    # 'NAIROBE': 'NAIROBI',\n",
    "    # Add your corrections here\n",
    "    \"ADDIS ABEBA\": \"ADDIS ABABA\",\n",
    "    \"NABUNTURAN DDN\": \"NABUNTURAN DON\",\n",
    "    \"DAGUPAN CI\": \"DAGUPAN CITY\",\n",
    "    \"STO TOMAS DVO\": \"STO TOMAS DAVAO\",\n",
    "    \"STO TOMAS DVO DN\": \"STO TOMAS DAVAO\",\n",
    "    \"STO TOMAS DAVAD\": \"STO TOMAS DAVAO\",\n",
    "    \"STO TOMAS DVD\": \"STO TOMAS DAVAO\",\n",
    "    \"S-BULLONES BOHO\": \"S BULLONES BOHO\",\n",
    "}\n",
    "\n",
    "# Apply corrections to the places_to_add DataFrame\n",
    "places_to_add['name'] = places_to_add['name'].apply(lambda x: corrections.get(x, x))\n",
    "\n",
    "# Remove duplicates after corrections\n",
    "places_to_add = places_to_add.drop_duplicates(subset=['name', 'country_code'])\n",
    "\n",
    "# Update combined_cities with corrected names\n",
    "combined_cities = pd.concat([existing_cities, places_to_add]).drop_duplicates(subset=['name'])\n",
    "\n",
    "# Save updated custom_cities.csv\n",
    "combined_cities.to_csv(custom_cities_path, index=False)\n",
    "\n",
    "print(f\"Updated custom_cities.csv with corrections\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
