{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.utils.results_utils import mapper\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"static\"\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        try:\n",
    "            temp = pd.read_excel(os.path.join(folder, file), sheet_name=\"Data\")\n",
    "        except:\n",
    "            temp = pd.read_excel(os.path.join(folder, file), sheet_name=\"Sheet 1\")\n",
    "        df = pd.concat([df, temp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[[\"Maid’s ID\", \"Modified Field\", \"Maid’s Nationality\", \"Agent Value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = target[target[\"Modified Field\"] == \"Birth Place\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name  Maid’s ID\n",
      "0      A CASTANEDA NV  [87863.0]\n",
      "1      A LISTA IFUGAO  [81935.0]\n",
      "2             ABAREBO  [82048.0]\n",
      "3             ABEGORA  [80776.0]\n",
      "4               ABELA  [84834.0]\n",
      "...               ...        ...\n",
      "4134            ZIWAY  [82072.0]\n",
      "4135  ZUMARRAGA SAMAR  [87356.0]\n",
      "4136       ZVISHAVANE  [86988.0]\n",
      "4137   Zamboanga City  [75298.0]\n",
      "4138            Ziway  [76259.0]\n",
      "\n",
      "[4139 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique places and nationalities\n",
    "places_unique = places[[\"Maid’s ID\", \"Maid’s Nationality\", \"Agent Value\"]].drop_duplicates(subset=[\"Maid’s Nationality\", \"Agent Value\"])\n",
    "\n",
    "# Normalize nationality to country code using mapper\n",
    "def get_country_code(nationality):\n",
    "    # Use fuzzy matching to find the closest key in mapper\n",
    "    matched_country, score = process.extractOne(nationality, mapper.keys())\n",
    "    return mapper.get(matched_country, \"XXX\")\n",
    "\n",
    "places_unique[\"country_code\"] = places_unique[\"Maid’s Nationality\"].apply(get_country_code)\n",
    "\n",
    "# Prepare DataFrame for custom_cities.csv format\n",
    "places_to_add = places_unique[[\"Agent Value\", \"country_code\", \"Maid’s ID\"]].rename(columns={\"Agent Value\": \"name\"})\n",
    "place_ids = places_to_add[['name', 'Maid’s ID']]\n",
    "place_ids = place_ids.groupby('name').agg(lambda x: list(x)).reset_index()\n",
    "\n",
    "# Load existing custom_cities.csv\n",
    "custom_cities_path = os.path.join(folder, \"custom_cities.csv\")\n",
    "if os.path.exists(custom_cities_path):\n",
    "    existing_cities = pd.read_csv(custom_cities_path)\n",
    "else:\n",
    "    existing_cities = pd.DataFrame(columns=[\"name\", \"country_code\"])\n",
    "\n",
    "# Find new places that are not in the existing custom_cities.csv\n",
    "existing_places = set(existing_cities[\"name\"].str.upper())\n",
    "places_to_add[\"name\"] = places_to_add[\"name\"].str.upper()\n",
    "new_places = places_to_add[~places_to_add[\"name\"].isin(existing_places)]\n",
    "\n",
    "# Combine existing and new places\n",
    "combined_cities = pd.concat([existing_cities, new_places]).drop_duplicates(subset=[\"name\"])\n",
    "\n",
    "# Save updated custom_cities.csv\n",
    "combined_cities.to_csv(custom_cities_path, index=False)\n",
    "\n",
    "# Display how many new places were added\n",
    "len(new_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G GENEROSO DV OR 1 [[85982.0]] G GENEROSO DVO OR 1 [[75564.0]] \n",
      "SN FERNANDO CEBU 1 [[77522.0]] SAN FERNANDO CEBU 1 [[89837.0]] \n",
      "MATALAM NO COT 1 [[86862.0]] MATALAM N COT 1 [[88297.0]] \n",
      "SANCHEZ MIRA CAG 1 [[86967.0]] SANCHEZ MIRA CAGE 1 [[92705.0]] \n",
      "ALLANERA N ECIJA 1 [[86928.0]] LLANERA N ECIJA 1 [[84366.0]] \n",
      "KIDAPAWAN NO COT 1 [[84771.0]] KIDAPAWAN NO CO 1 [[91712.0]] \n",
      "SAN FERNANDO PMP 1 [[85775.0]] SAN FERNANDO PAMP 1 [[87102.0]] \n",
      "SAN LUIS PAMPANGA 1 [[87416.0]] SN LUIS PAMPANGA 1 [[85282.0]] \n",
      "LAGUINDINGAN MO 1 [[85280.0]] LAGUINDINGAN M O 1 [[86057.0]] \n",
      "BANGA S COTABATO 1 [[84942.0]] BANGA SO COTABATO 1 [[91688.0]] \n",
      "GAPAN N ECIJA 1 [[80319.0]] GAPAN NECIJA 1 [[86087.0]] \n",
      "KALIBO AKLAN 1 [[80321.0]] KALIBO KLAN 1 [[80321.0]] \n",
      "VALENCIA BKN 1 [[82897.0]] VALECIA BKN 1 [[93211.0]] \n",
      "MINGLANILA CEBU 1 [[80334.0]] MINGLANILLA CEBU 1 [[84856.0]] \n",
      "LAPU LAPU CEBU 2 [[84450.0]] LAPULAPU CEBU 1 [[81000.0]] \n",
      "APARRI CAGAYAN 1 [[87029.0]] APARRI AGAYAN 1 [[82652.0]] \n",
      "DUPAX DN N VIZ 2 [[83243.0]] DUPA DN N VIZ 1 [[90857.0]] \n",
      "SN JUAN BATANGAS 2 [[86175.0]] SAN JUAN BATANGAS 1 [[85471.0]] \n",
      "SN FRANCISCO ADS 1 [[87103.0]] SAN FRANCISCO ADS 1 [[83020.0]] \n",
      "DATU SINSUAT MGD 2 [[86785.0]] DATU SINSUAT MGDE 1 [[91044.0]] \n",
      "LAS NIEVES ADN 1 [[82205.0]] LAS NIEVES AD 1 [[83776.0]] \n",
      "S BENEDICTO N OC 1 [[87203.0]] S BENEDICTON OC 1 [[87203.0]] \n",
      "CALATRAVA NEG OC 1 [[80649.0]] CALATRAVA NEG OCC 1 [[86463.0]] \n",
      "TALAVERA N ECIJA 1 [[82777.0]] TALAVERA NECIJA 1 [[88478.0]] \n",
      "MLANG NO COT 1 [[86219.0]] MLANG N COT 1 [[88591.0]] \n",
      "ESPERANZA S KUD 2 [[85468.0]] ESPERANZAS KUD 1 [[79231.0]] \n",
      "DATU PAGLAS MGD 1 [[80860.0]] DATU PAGLAS MD 1 [[80860.0]] \n",
      "TALIPAO SLU 1 [[86912.0]] TALIPAO SULU 1 [[77606.0]] \n",
      "OROQUIETA CITY 1 [[81061.0]] OROQUETA CITY 1 [[83775.0]] \n",
      "BACUJAG SGO DN 1 [[86161.0]] BACUAG SGO DN 1 [[93217.0]] \n",
      "ARAYAT PAMPANGA 1 [[80991.0]] RAYAT PAMPANGA 1 [[78100.0]] \n",
      "STA FE N VIZ 1 [[86918.0]] STA FEN VIZ 1 [[77923.0]] \n",
      "STO DOMINGO I S 1 [[82628.0]] STO DOMINGO IS 1 [[82628.0]] \n",
      "SN ILDEFONSO BUL 1 [[83057.0]] SAN ILDEFONSO BUL 1 [[77264.0]] \n",
      "CALAPAN OR MDO 1 [[85789.0]] CALAPAN OR MDOD 1 [[88856.0]] \n",
      "MANAY DVAO OR 1 [[83890.0]] MANAY DVO OR 1 [[90633.0]] \n",
      "DAANBANTAYAN CEB 1 [[86023.0]] DAANBANTAYAN CEBU 1 [[88625.0]] \n",
      "D O SINSUAT MGD 1 [[88544.0]] DO SINSUAT MGD 1 [[92813.0]] \n",
      "CLAVERIA CAGAYA 1 [[90569.0]] CLAVERIA CAGAYAN 1 [[89506.0]] \n",
      "CAG DE ORO MS OR 1 [[88110.0]] CAG DE ORO MIS OR 1 [[75317.0]] \n",
      "SN ISIDRO NO SMR 1 [[79980.0]] SAN ISIDRO NO SMR 1 [[71386.0]] \n",
      "PULUPANDAN N OC 1 [[91721.0]] PULUPANDANN OC 1 [[79933.0]] \n",
      "ALAMADA NO COT 1 [[79304.0]] ALAMADA N COT 1 [[84916.0]] \n",
      "STA CATALINA IS 1 [[88074.0]] STA CATALINA I S 1 [[77920.0]] \n",
      "SN MIGUEL SGO DS 1 [[74885.0]] SAN MIGUEL SGO DS 1 [[92177.0]] \n"
     ]
    }
   ],
   "source": [
    "# Identify similar city names within each country code\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set similarity threshold\n",
    "similarity_threshold = 95  # Adjust as needed (higher = stricter matching)\n",
    "\n",
    "# Group places by country code\n",
    "country_groups = places_to_add.groupby('country_code')\n",
    "\n",
    "# Dictionary to store similar place clusters for each country\n",
    "similar_places = defaultdict(list)\n",
    "\n",
    "# Process each country's places\n",
    "for country_code, group in country_groups:\n",
    "    places_list = group['name'].tolist()\n",
    "    \n",
    "    # Skip processing if too few places\n",
    "    if len(places_list) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Find similar places within this country\n",
    "    processed = set()\n",
    "    \n",
    "    for i, place1 in enumerate(places_list):\n",
    "        if place1 in processed:\n",
    "            continue\n",
    "            \n",
    "        cluster = [place1]\n",
    "        processed.add(place1)\n",
    "        \n",
    "        for place2 in places_list[i+1:]:\n",
    "            if place2 in processed:\n",
    "                continue\n",
    "                \n",
    "            # Calculate similarity ratio\n",
    "            similarity = fuzz.ratio(place1, place2)\n",
    "            \n",
    "            # If similar enough, add to cluster\n",
    "            if similarity >= similarity_threshold:\n",
    "                cluster.append(place2)\n",
    "                processed.add(place2)\n",
    "        \n",
    "        # Store cluster if it contains multiple places\n",
    "        if len(cluster) > 1:\n",
    "            similar_places[country_code].append(cluster)\n",
    "\n",
    "place_counts = places_to_add['name'].value_counts().to_dict()\n",
    "\n",
    "# Create a DataFrame with all similar place clusters for easier inspection\n",
    "similar_df_rows = []\n",
    "country = \"PHL\"\n",
    "clusters = similar_places[country]\n",
    "\n",
    "for cluster in clusters:\n",
    "    for place in cluster:\n",
    "        print(place, place_counts.get(place, 0), place_ids[place_ids['name'] == place]['Maid’s ID'].tolist(), end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reviewing similar_places.csv, create a mapping of misspelled names to correct names\n",
    "# For example:\n",
    "corrections = {\n",
    "    # 'MISSPELLED': 'CORRECT',\n",
    "    # 'NAIROBE': 'NAIROBI',\n",
    "    # Add your corrections here\n",
    "    \"ADDIS ABEBA\": \"ADDIS ABABA\",\n",
    "    \"NABUNTURAN DDN\": \"NABUNTURAN DON\",\n",
    "    \"DAGUPAN CI\": \"DAGUPAN CITY\",\n",
    "    \"STO TOMAS DVO\": \"STO TOMAS DAVAO\",\n",
    "    \"STO TOMAS DVO DN\": \"STO TOMAS DAVAO\",\n",
    "    \"STO TOMAS DAVAD\": \"STO TOMAS DAVAO\",\n",
    "    \"STO TOMAS DVD\": \"STO TOMAS DAVAO\",\n",
    "    \"S-BULLONES BOHO\": \"S BULLONES BOHO\",\n",
    "}\n",
    "\n",
    "# Apply corrections to the places_to_add DataFrame\n",
    "places_to_add['name'] = places_to_add['name'].apply(lambda x: corrections.get(x, x))\n",
    "\n",
    "# Remove duplicates after corrections\n",
    "places_to_add = places_to_add.drop_duplicates(subset=['name', 'country_code'])\n",
    "\n",
    "# Update combined_cities with corrected names\n",
    "combined_cities = pd.concat([existing_cities, places_to_add]).drop_duplicates(subset=['name'])\n",
    "\n",
    "# Save updated custom_cities.csv\n",
    "combined_cities.to_csv(custom_cities_path, index=False)\n",
    "\n",
    "print(f\"Updated custom_cities.csv with corrections\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
